   1.Hello TensorFlow.js (CO1 – Understand)
1. Create tensors of different dimensions (scalar, vector, matrix) and print them.
2. Perform element-wise addition and multiplication on two vectors.
3. Demonstrate tensor reshaping and explain the difference between reshape() and
flatten().
   2. Linear Regression with Synthetic Data (CO2 – Analyze)
1. Train a regression model on synthetic data and plot predicted vs actual values.
2. Experiment with different learning rates and analyze their effect on convergence.
3. Predict values for unseen inputs and compare with expected results.
   3. Image Classification with Pre-trained MobileNet (CO3 – Apply)
1. Load MobileNet and classify a static image; display top-3 predictions.
2. Test classification accuracy on at least 5 different images.
3. Compare MobileNet predictions with another pre-trained model (e.g., ResNet).
   4. Digit Recognition (MNIST Dataset) (CO2 – Analyze)
1. Train a CNN on MNIST and report accuracy after 5 epochs.
2. Draw a digit on a canvas and classify it using the trained model.
3. Compare performance between a CNN and a simple dense network.
5. Webcam-based Object Detection (CO3 – Apply)
1. Capture webcam frames and classify objects using MobileNet.
2. Overlay classification labels on the video feed.
3. Measure FPS and analyze performance impact of real-time inference.
   6. Text Sentiment Analysis (CO2 – Analyze)
1. Train a sentiment classifier on a small dataset of positive/negative sentences.
2. Test the model on custom sentences and interpret confidence scores.
3. Compare performance of RNN vs a simple dense network for sentiment tasks.
   7. Pose Detection with PoseNet (CO3 – Apply)
1. Detect human pose keypoints from webcam feed and visualize skeleton.
2. Count repetitions of a simple exercise (e.g., squats) using keypoint angles.
3. Analyze accuracy differences between single-pose and multi-pose detection.
   8. Transfer Learning with Images (CO4 – Create)
1. Retrain MobileNet for a custom dataset (e.g., fruits) with 3 categories.
2. Evaluate accuracy on validation data and report confusion matrix.
3. Add new categories incrementally and retrain; analyze performance changes.
   9. Real-time Gesture Control (CO4 – Create)
1. Implement gesture-based play/pause control for a video element.
2. Extend to volume control using hand position (up/down).
3. Design a custom gesture (e.g., thumbs up) and map it to a browser action.
   10. Deploying a Model in Browser (CO3 – Apply)
1. Train a small model and save it to LocalStorage.
2. Reload the model and verify predictions match the original.
3. Export the model to files and re-import it; test predictions again.
